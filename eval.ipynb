{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n",
      "available GPU(s): 1\n",
      "0: {'name': 'GeForce RTX 2080 Ti', 'capability': [7, 5], 'total_momory': 10.76, 'sm_count': 68}\n",
      "\n",
      "device: cuda\n",
      "Automatic mixed precision (AMP) is enabled!\n",
      "Nvidia DALI is utilized!\n",
      "evaluating...\n",
      "iter: 93.6, total: 77.0, model: 70.9\n",
      "all gather: 0.0s\n",
      "accumulate: 32.3s\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.529\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.371\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.396\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.447\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.440\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.510\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.590\n",
      "\n",
      "\n",
      "total time of this evaluation: 53.19 s, speed: 451.11 FPS\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import yolo\n",
    "\n",
    "    \n",
    "def main(args):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and args.use_cuda else \"cpu\")\n",
    "    cuda = device.type == \"cuda\"\n",
    "    if cuda: yolo.get_gpu_prop(show=True)\n",
    "    print(\"\\ndevice: {}\".format(device))\n",
    "    \n",
    "    args.amp = False\n",
    "    if cuda and torch.__version__ >= \"1.6.0\":\n",
    "        capability = torch.cuda.get_device_capability()[0]\n",
    "        if capability >= 7: # 7 refers to RTX series GPUs\n",
    "            args.amp = True\n",
    "            print(\"Automatic mixed precision (AMP) is enabled!\")\n",
    "            \n",
    "    # ---------------------- prepare data loader ------------------------------- #\n",
    "    \n",
    "    DALI = cuda & yolo.DALI & (args.dataset == \"coco\")\n",
    "    \n",
    "    if DALI:\n",
    "        print(\"Nvidia DALI is utilized!\")\n",
    "        d_test = yolo.DALICOCODataLoader(\n",
    "            args.file_root, args.ann_file, args.batch_size, collate_fn=yolo.collate_wrapper)\n",
    "    else:\n",
    "        dataset_test = yolo.datasets(args.dataset, args.file_root, args.ann_file, train=True) # set train=True for eval\n",
    "        sampler_test = torch.utils.data.SequentialSampler(dataset_test)\n",
    "\n",
    "        batch_sampler_test = yolo.GroupedBatchSampler(\n",
    "            sampler_test, dataset_test.aspect_ratios, args.batch_size)\n",
    "        \n",
    "        args.num_workers = min(os.cpu_count() // 2, 8, args.batch_size if args.batch_size > 1 else 0)\n",
    "        data_loader_test = torch.utils.data.DataLoader(\n",
    "            dataset_test, batch_sampler=batch_sampler_test, num_workers=args.num_workers,  \n",
    "            collate_fn=yolo.collate_wrapper, pin_memory=cuda)\n",
    "\n",
    "        d_test = yolo.DataPrefetcher(data_loader_test) if cuda else data_loader_test\n",
    "    \n",
    "    # -------------------------------------------------------------------------- #\n",
    "\n",
    "    yolo.setup_seed(3)\n",
    "    \n",
    "    model_sizes = {\"small\": (0.33, 0.5), \"medium\": (0.67, 0.75), \"large\": (1, 1), \"extreme\": (1.33, 1.25)}\n",
    "    num_classes = len(d_test.dataset.classes)\n",
    "    model = yolo.YOLOv5(num_classes, model_sizes[args.model_size], **args.kwargs).to(device)\n",
    "    model.head.eval_with_loss = args.eval_with_loss\n",
    "    \n",
    "    checkpoint = torch.load(args.ckpt_path, map_location=device)\n",
    "    if \"ema\" in checkpoint:\n",
    "        model.load_state_dict(checkpoint[\"ema\"][0])\n",
    "        print(checkpoint[\"eval_info\"])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "\n",
    "    model.fuse()\n",
    "    print(\"evaluating...\")\n",
    "    B = time.time()\n",
    "    eval_output, iter_eval = yolo.evaluate(model, d_test, device, args, evaluation=args.evaluation)\n",
    "    B = time.time() - B\n",
    "    print(eval_output)\n",
    "    print(\"\\ntotal time of this evaluation: {:.2f} s, speed: {:.2f} FPS\".format(B, args.batch_size / iter_eval))\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args([]) # [] is needed when using Jupyter Notebook.\n",
    "    \n",
    "    args.use_cuda = True\n",
    "    \n",
    "    args.dataset = \"coco\"\n",
    "    args.file_root = \"/data/nextcloud/dbc2017/files/jupyter/input/data/coco2017/val2017\"\n",
    "    args.ann_file = \"/data/nextcloud/dbc2017/files/jupyter/input/data/coco2017/annotations/instances_val2017.json\"\n",
    "    args.ckpt_path = \"/data/nextcloud/dbc2017/files/jupyter/data/ckpts/yolov5s_official_2cf45318.pth\"\n",
    "    args.results = os.path.join(os.path.dirname(args.ckpt_path), \"results.json\")\n",
    "    \n",
    "    args.batch_size = 32\n",
    "    args.iters = -1\n",
    "    \n",
    "    args.model_size = \"small\"\n",
    "    args.kwargs = {\"img_sizes\": 640, \"score_thresh\": 0.1, \"detections\": 100} # mAP 34.6 FPS 451\n",
    "    #args.kwargs = {\"img_sizes\": 672, \"score_thresh\": 0.001, \"detections\": 300} # mAP 36.1. take more(2x-4x) time in total\n",
    "    args.evaluation = True\n",
    "    args.eval_with_loss = False\n",
    "    \n",
    "    main(args)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
